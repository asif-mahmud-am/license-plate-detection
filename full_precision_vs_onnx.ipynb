{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Load Time: 0.1527 seconds\n",
      "Memory Usage During Model Load: Current = 1.49 MB, Peak = 2.03 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 license_plate, 233.7ms\n",
      "Speed: 9.0ms preprocess, 233.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 2.5323 seconds\n",
      "Output saved to: ./output_yolo.jpg\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import psutil\n",
    "import tracemalloc\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Start tracking memory\n",
    "tracemalloc.start()\n",
    "\n",
    "# Load the model and measure the time\n",
    "start_time = time.time()\n",
    "model = YOLO('./models/license_plate_detector.pt')  # Path to trained YOLOv8 model\n",
    "model_load_time = time.time() - start_time\n",
    "\n",
    "# Capture memory usage\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "print(f\"Model Load Time: {model_load_time:.4f} seconds\")\n",
    "print(f\"Memory Usage During Model Load: Current = {current / 1024 / 1024:.2f} MB, Peak = {peak / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Input image\n",
    "input_image = cv2.imread('car_image.jpg')  # Path to the input image\n",
    "assert input_image is not None, \"Input image not found!\"\n",
    "\n",
    "# Inference and measure time\n",
    "start_time = time.time()\n",
    "results = model(input_image)\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "# Annotate detections\n",
    "annotated_image = results[0].plot()\n",
    "\n",
    "# Save the output image\n",
    "output_path = './output_yolo.jpg'\n",
    "cv2.imwrite(output_path, annotated_image)\n",
    "print(f\"Inference Time: {inference_time:.4f} seconds\")\n",
    "print(f\"Output saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Model Load Time: 0.3940 seconds\n",
      "Memory Usage During Model Load: Current = 0.00 MB, Peak = 0.01 MB\n",
      "Inference Time: 0.0843 seconds\n",
      "Output saved to: ./output_onnx.jpg\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import psutil\n",
    "import tracemalloc\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Start tracking memory\n",
    "tracemalloc.start()\n",
    "\n",
    "# Load ONNX model and measure the time\n",
    "start_time = time.time()\n",
    "onnx_model_path = './models/license_plate_detector.onnx'  # Path to ONNX model\n",
    "ort_session = ort.InferenceSession(onnx_model_path)\n",
    "model_load_time = time.time() - start_time\n",
    "\n",
    "# Capture memory usage\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "print(f\"ONNX Model Load Time: {model_load_time:.4f} seconds\")\n",
    "print(f\"Memory Usage During Model Load: Current = {current / 1024 / 1024:.2f} MB, Peak = {peak / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Input image\n",
    "input_image = cv2.imread('car_image.jpg')  # Path to the input image\n",
    "assert input_image is not None, \"Input image not found!\"\n",
    "\n",
    "# Preprocess image for ONNX (resize and normalize)\n",
    "input_shape = (640, 640)  # Assumes the model input size is 640x640\n",
    "resized_image = cv2.resize(input_image, input_shape)\n",
    "input_tensor = resized_image.transpose(2, 0, 1).astype('float32')  # Convert to CHW format\n",
    "input_tensor = np.expand_dims(input_tensor, axis=0) / 255.0  # Add batch dimension and normalize\n",
    "\n",
    "# Inference and measure time\n",
    "start_time = time.time()\n",
    "outputs = ort_session.run(None, {'images': input_tensor})\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "# Postprocess the outputs\n",
    "detections = outputs[0][0]\n",
    "for detection in detections:\n",
    "    x, y, w, h, confidence, class_id = detection[:6]\n",
    "    if confidence > 0.5:  # Confidence threshold\n",
    "        x_min = int((x - w / 2) * input_image.shape[1] / input_shape[0])\n",
    "        y_min = int((y - h / 2) * input_image.shape[0] / input_shape[1])\n",
    "        x_max = int((x + w / 2) * input_image.shape[1] / input_shape[0])\n",
    "        y_max = int((y + h / 2) * input_image.shape[0] / input_shape[1])\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(input_image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "        label = f\"LP: {confidence:.2f}\"\n",
    "        cv2.putText(input_image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Save the output image\n",
    "output_path = './output_onnx.jpg'\n",
    "cv2.imwrite(output_path, input_image)\n",
    "print(f\"Inference Time: {inference_time:.4f} seconds\")\n",
    "print(f\"Output saved to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indoor-object-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
